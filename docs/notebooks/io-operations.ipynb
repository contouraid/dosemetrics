{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e959e9e7",
   "metadata": {},
   "source": [
    "## 1. Download Example Data from HuggingFace\n",
    "\n",
    "First, we'll download the anonymized example dataset from HuggingFace. This data includes:\n",
    "- Synthetic CT images (for spatial reference)\n",
    "- Real dose distributions\n",
    "- Real structure masks (organs at risk and targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ba9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "# Download the dataset (cached locally after first download)\n",
    "data_path = snapshot_download(\n",
    "    repo_id=\"contouraid/dosemetrics-data\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "data_path = Path(data_path)\n",
    "print(f\"✓ Data downloaded to: {data_path}\")\n",
    "print(f\"\\nAvailable datasets:\")\n",
    "for item in data_path.iterdir():\n",
    "    if item.is_dir():\n",
    "        print(f\"  - {item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4cee2",
   "metadata": {},
   "source": [
    "## 2. Basic Data Loading\n",
    "\n",
    "The simplest way to load data is using `read_dose_and_mask_files()`. This function:\n",
    "- Automatically finds the dose file\n",
    "- Loads all structure masks\n",
    "- Returns a dose array and StructureSet object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b317f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dosemetrics import read_dose_and_mask_files\n",
    "\n",
    "# Load test subject data\n",
    "subject_path = data_path / \"longitudinal\" / \"time_point_1\"\n",
    "dose, structures = read_dose_and_mask_files(subject_path)\n",
    "\n",
    "print(f\"✓ Loaded dose distribution\")\n",
    "print(f\"  Shape: {dose.shape}\")\n",
    "print(f\"  Data type: {dose.dtype}\")\n",
    "print(f\"  Dose range: {dose.min():.2f} - {dose.max():.2f} Gy\")\n",
    "print(f\"\\n✓ Loaded {len(structures.structure_names)} structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7055b",
   "metadata": {},
   "source": [
    "## 3. Working with the StructureSet\n",
    "\n",
    "The `StructureSet` object provides a convenient interface for accessing structure masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available structures\n",
    "print(\"Available structures:\")\n",
    "for i, name in enumerate(structures.structure_names, 1):\n",
    "    print(f\"  {i:2d}. {name}\")\n",
    "\n",
    "# Get a specific structure mask\n",
    "ptv_mask = structures.get_structure_mask(\"PTV\")\n",
    "print(f\"\\nPTV mask:\")\n",
    "print(f\"  Shape: {ptv_mask.shape}\")\n",
    "print(f\"  Data type: {ptv_mask.dtype}\")\n",
    "print(f\"  Unique values: {len(ptv_mask.unique())} (binary mask)\")\n",
    "\n",
    "# Check which structures are available\n",
    "if structures.has_structure(\"BrainStem\"):\n",
    "    print(\"\\n✓ BrainStem structure is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0988133",
   "metadata": {},
   "source": [
    "## 4. Loading Individual Files\n",
    "\n",
    "You can also load individual NIfTI files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab109cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dosemetrics import read_from_nifti\n",
    "import nibabel as nib\n",
    "\n",
    "# Load dose file with metadata\n",
    "dose_file = subject_path / \"Dose.nii.gz\"\n",
    "dose_nii = nib.load(dose_file)\n",
    "\n",
    "# Get metadata\n",
    "print(\"Dose file metadata:\")\n",
    "print(f\"  Dimensions: {dose_nii.shape}\")\n",
    "print(f\"  Voxel spacing (mm): {dose_nii.header.get_zooms()}\")\n",
    "print(f\"  Data type: {dose_nii.get_data_dtype()}\")\n",
    "\n",
    "# Load as numpy array\n",
    "dose_array = read_from_nifti(str(dose_file))\n",
    "print(f\"\\nDose array:\")\n",
    "print(f\"  Shape: {dose_array.shape}\")\n",
    "print(f\"  Mean dose: {dose_array.mean():.2f} Gy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869ba8b",
   "metadata": {},
   "source": [
    "## 5. Loading Multiple Files\n",
    "\n",
    "Load all structure masks from a folder at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dosemetrics.io import read_structures_from_folder\n",
    "\n",
    "# Load all structure masks\n",
    "structures_dict = read_structures_from_folder(subject_path)\n",
    "\n",
    "print(f\"Loaded {len(structures_dict)} structure masks:\")\n",
    "for name, mask in structures_dict.items():\n",
    "    voxel_count = (mask > 0).sum()\n",
    "    print(f\"  {name:20s} - {voxel_count:6d} voxels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d82eb",
   "metadata": {},
   "source": [
    "## 6. Comparing Two Treatment Plans\n",
    "\n",
    "Load data from two different plans for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first plan\n",
    "plan1_path = data_path / \"longitudinal\" / \"time_point_1\"\n",
    "dose1, structures1 = read_dose_and_mask_files(plan1_path)\n",
    "\n",
    "# Load second plan\n",
    "plan2_path = data_path / \"longitudinal\" / \"time_point_2\"\n",
    "dose2, structures2 = read_dose_and_mask_files(plan2_path)\n",
    "\n",
    "print(\"Plan 1:\")\n",
    "print(f\"  Dose shape: {dose1.shape}\")\n",
    "print(f\"  Max dose: {dose1.max():.2f} Gy\")\n",
    "print(f\"  Structures: {len(structures1.structure_names)}\")\n",
    "\n",
    "print(\"\\nPlan 2:\")\n",
    "print(f\"  Dose shape: {dose2.shape}\")\n",
    "print(f\"  Max dose: {dose2.max():.2f} Gy\")\n",
    "print(f\"  Structures: {len(structures2.structure_names)}\")\n",
    "\n",
    "# Compare dose distributions\n",
    "import numpy as np\n",
    "dose_diff = dose2 - dose1\n",
    "print(f\"\\nDose difference:\")\n",
    "print(f\"  Mean: {np.mean(dose_diff):.2f} Gy\")\n",
    "print(f\"  Std: {np.std(dose_diff):.2f} Gy\")\n",
    "print(f\"  Range: [{dose_diff.min():.2f}, {dose_diff.max():.2f}] Gy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c168ed9",
   "metadata": {},
   "source": [
    "## 7. Comparing Dose Distributions\n",
    "\n",
    "You can compare dose distributions between different time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5bd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dose from time point 2\n",
    "time_point_2_path = data_path / \"longitudinal\" / \"time_point_2\"\n",
    "dose2 = read_from_nifti(str(time_point_2_path / \"Dose.nii.gz\"))\n",
    "\n",
    "print(\"Time Point 1 dose:\")\n",
    "print(f\"  Mean: {dose.mean():.2f} Gy\")\n",
    "print(f\"  Max: {dose.max():.2f} Gy\")\n",
    "\n",
    "print(\"\\nTime Point 2 dose:\")\n",
    "print(f\"  Mean: {dose2.mean():.2f} Gy\")\n",
    "print(f\"  Max: {dose2.max():.2f} Gy\")\n",
    "\n",
    "# Compare in PTV region\n",
    "ptv_mask = structures.get_structure_mask(\"PTV\")\n",
    "ptv_mask_np = ptv_mask.numpy() > 0\n",
    "\n",
    "dose1_in_ptv = dose[ptv_mask_np]\n",
    "dose2_in_ptv = dose2[ptv_mask_np]\n",
    "\n",
    "print(\"\\nIn PTV region:\")\n",
    "print(f\"  Time point 1 mean dose: {dose1_in_ptv.mean():.2f} Gy\")\n",
    "print(f\"  Time point 2 mean dose: {dose2_in_ptv.mean():.2f} Gy\")\n",
    "print(f\"  Difference: {abs(dose2_in_ptv.mean() - dose1_in_ptv.mean()):.2f} Gy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec428aa2",
   "metadata": {},
   "source": [
    "## 8. Inspecting Data Structure\n",
    "\n",
    "Explore what files are available in a subject folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def inspect_subject_folder(folder_path):\n",
    "    \"\"\"Display the structure of a subject folder.\"\"\"\n",
    "    print(f\"Contents of {folder_path.name}:\")\n",
    "    print(\"\\nDose files:\")\n",
    "    for f in sorted(folder_path.glob(\"*Dose*.nii.gz\")):\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {f.name:30s} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    print(\"\\nStructure files:\")\n",
    "    for f in sorted(folder_path.glob(\"*.nii.gz\")):\n",
    "        if \"Dose\" not in f.name and \"CT\" not in f.name:\n",
    "            size_mb = f.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  {f.name:30s} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    print(\"\\nImaging files (synthetic):\")\n",
    "    for f in sorted(folder_path.glob(\"CT*.nii.gz\")):\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {f.name:30s} ({size_mb:.2f} MB)\")\n",
    "\n",
    "inspect_subject_folder(subject_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce14d1d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. ✓ Download data from HuggingFace datasets\n",
    "2. ✓ Load dose distributions and structure masks\n",
    "3. ✓ Use the StructureSet API\n",
    "4. ✓ Read individual NIfTI files\n",
    "5. ✓ Compare multiple treatment plans\n",
    "6. ✓ Work with predicted vs actual doses\n",
    "7. ✓ Inspect data structure\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Computing Metrics**: Learn how to compute DVHs, quality indices, and dose constraints\n",
    "- **Exporting Results**: Generate reports, plots, and export data\n",
    "- **API Documentation**: Explore the full [DoseMetrics API](https://contouraid.github.io/dosemetrics/api/)\n",
    "\n",
    "## References\n",
    "\n",
    "- [DoseMetrics Documentation](https://contouraid.github.io/dosemetrics/)\n",
    "- [Dataset on HuggingFace](https://huggingface.co/datasets/contouraid/dosemetrics-examples)\n",
    "- [GitHub Repository](https://github.com/contouraid/dosemetrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
