{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f88309",
   "metadata": {},
   "source": [
    "## 1. Setup: Download Sample Data\n",
    "\n",
    "We'll use the test dataset from HuggingFace which includes NIfTI format radiotherapy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d01ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amithkamath/Repositories/ContourAId/dosemetrics/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 165 files: 100%|██████████| 165/165 [00:00<00:00, 11486.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data downloaded to: /Users/amithkamath/.cache/huggingface/hub/datasets--contouraid--dosemetrics-data/snapshots/839ceab7ba71766265fd6a637fe799341bb0364f\n",
      "\n",
      "Available datasets:\n",
      "  - test_subject\n",
      "  - longitudinal\n",
      "  - dicom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Download the dataset (cached locally after first download)\n",
    "data_path = snapshot_download(\n",
    "    repo_id=\"contouraid/dosemetrics-data\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "data_path = Path(data_path)\n",
    "print(f\"✓ Data downloaded to: {data_path}\")\n",
    "print(f\"\\nAvailable datasets:\")\n",
    "for item in data_path.iterdir():\n",
    "    if item.is_dir():\n",
    "        print(f\"  - {item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec402e36",
   "metadata": {},
   "source": [
    "## 2. Basic Data Loading\n",
    "\n",
    "The simplest way to load NIfTI data is using `load_structure_set()`. This function:\n",
    "- Automatically detects the NIfTI format\n",
    "- Loads the dose file and all structure masks\n",
    "- Returns a StructureSet object with convenient access methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8ca30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded NIfTI data from: /Users/amithkamath/.cache/huggingface/hub/datasets--contouraid--dosemetrics-data/snapshots/839ceab7ba71766265fd6a637fe799341bb0364f/test_subject\n",
      "\n",
      "Number of structures: 16\n",
      "Structure names: ['OpticNerve_L', 'Cochlea_R', 'CTV', 'Lens_L', 'OpticNerve_R', 'Cochlea_L', 'Lens_R', 'PTV', 'LacrimalGland_L', 'Eye_R', 'LacrimalGland_R', 'Chiasm', 'GTV', 'Brain', 'Eye_L', 'Brainstem']\n"
     ]
    }
   ],
   "source": [
    "from dosemetrics.io import load_structure_set\n",
    "\n",
    "# Load test subject data (NIfTI format)\n",
    "subject_path = data_path / \"test_subject\"\n",
    "structures = load_structure_set(subject_path)\n",
    "\n",
    "print(f\"✓ Loaded NIfTI data from: {subject_path}\")\n",
    "print(f\"\\nNumber of structures: {len(structures)}\")\n",
    "print(f\"Structure names: {structures.structure_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9881d2",
   "metadata": {},
   "source": [
    "## 3. Working with the StructureSet\n",
    "\n",
    "The `StructureSet` object provides convenient access to structure masks and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53a0cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available structures:\n",
      "------------------------------------------------------------\n",
      " 1. OpticNerve_L         -     104 voxels\n",
      " 2. Cochlea_R            -      10 voxels\n",
      " 3. CTV                  -  31,814 voxels\n",
      " 4. Lens_L               -      28 voxels\n",
      " 5. OpticNerve_R         -     134 voxels\n",
      " 6. Cochlea_L            -      28 voxels\n",
      " 7. Lens_R               -      33 voxels\n",
      " 8. PTV                  -  42,879 voxels\n",
      " 9. LacrimalGland_L      -      58 voxels\n",
      "10. Eye_R                -   1,267 voxels\n",
      "11. LacrimalGland_R      -      56 voxels\n",
      "12. Chiasm               -     120 voxels\n",
      "13. GTV                  -   9,312 voxels\n",
      "14. Brain                - 121,380 voxels\n",
      "15. Eye_L                -   1,179 voxels\n",
      "16. Brainstem            -   3,883 voxels\n",
      "\n",
      "PTV details:\n",
      "  Shape: (128, 128, 128)\n",
      "  Data type: bool\n",
      "  Non-zero voxels: 42,879\n",
      "  Min value: False\n",
      "  Max value: True\n",
      "\n",
      "Structure availability:\n",
      "  Brainstem           : ✓\n",
      "  Chiasm              : ✓\n",
      "  OpticNerve_L        : ✓\n"
     ]
    }
   ],
   "source": [
    "# List all available structures with details\n",
    "print(\"Available structures:\")\n",
    "print(\"-\" * 60)\n",
    "for i, name in enumerate(structures.structure_names, 1):\n",
    "    structure = structures.get_structure(name)\n",
    "    voxel_count = (structure.mask > 0).sum()\n",
    "    print(f\"{i:2d}. {name:20s} - {voxel_count:7,d} voxels\")\n",
    "\n",
    "# Get a specific structure mask\n",
    "ptv = structures.get_structure(\"PTV\")\n",
    "print(f\"\\nPTV details:\")\n",
    "print(f\"  Shape: {ptv.mask.shape}\")\n",
    "print(f\"  Data type: {ptv.mask.dtype}\")\n",
    "print(f\"  Non-zero voxels: {(ptv.mask > 0).sum():,}\")\n",
    "print(f\"  Min value: {ptv.mask.min()}\")\n",
    "print(f\"  Max value: {ptv.mask.max()}\")\n",
    "\n",
    "# Check if structures are available\n",
    "print(f\"\\nStructure availability:\")\n",
    "for check_name in [\"Brainstem\", \"Chiasm\", \"OpticNerve_L\"]:\n",
    "    available = check_name in structures\n",
    "    print(f\"  {check_name:20s}: {'✓' if available else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db27a9",
   "metadata": {},
   "source": [
    "## 4. Loading Dose Distribution (Recommended)\n",
    "\n",
    "Use the high-level `Dose` class to load dose files. This is the recommended approach for dose analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9519803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dose Distribution:\n",
      "------------------------------------------------------------\n",
      "  Name: Clinical\n",
      "  Dimensions: (128, 128, 128)\n",
      "  Max dose: 64.45 Gy\n",
      "  Mean dose: 7.95 Gy\n",
      "  Min dose: -0.92 Gy\n",
      "  Spacing: (2.0, 2.0, 2.0) mm\n",
      "  Origin: (92.70909881591797, 80.26853942871094, 52.468624114990234) mm\n"
     ]
    }
   ],
   "source": [
    "from dosemetrics import Dose\n",
    "\n",
    "# Load dose using the Dose class\n",
    "dose_file = subject_path / \"Dose.nii.gz\"\n",
    "dose = Dose.from_nifti(dose_file, name=\"Clinical\")\n",
    "\n",
    "print(\"Dose Distribution:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Name: {dose.name}\")\n",
    "print(f\"  Dimensions: {dose.shape}\")\n",
    "print(f\"  Max dose: {dose.max_dose:.2f} Gy\")\n",
    "print(f\"  Mean dose: {dose.mean_dose:.2f} Gy\")\n",
    "print(f\"  Min dose: {dose.min_dose:.2f} Gy\")\n",
    "print(f\"  Spacing: {dose.spacing} mm\")\n",
    "print(f\"  Origin: {dose.origin} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f188272",
   "metadata": {},
   "source": [
    "## 5. Computing Dose Statistics\n",
    "\n",
    "Combine the dose and structures to compute dose statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb52310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTV Dose Statistics:\n",
      "------------------------------------------------------------\n",
      "  Mean dose: 58.13 Gy\n",
      "  Max dose: 63.90 Gy\n",
      "  Min dose: 31.72 Gy\n",
      "  D95: 48.17 Gy\n",
      "  D50: 59.81 Gy\n",
      "  D05: 61.21 Gy\n",
      "\n",
      "DVH computed with 640 dose bins\n"
     ]
    }
   ],
   "source": [
    "from dosemetrics.metrics import dvh\n",
    "\n",
    "# Compute dose statistics for a structure\n",
    "ptv = structures.get_structure(\"PTV\")\n",
    "stats = dvh.compute_dose_statistics(dose, ptv)\n",
    "\n",
    "print(\"PTV Dose Statistics:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Mean dose: {stats['mean_dose']:.2f} Gy\")\n",
    "print(f\"  Max dose: {stats['max_dose']:.2f} Gy\")\n",
    "print(f\"  Min dose: {stats['min_dose']:.2f} Gy\")\n",
    "print(f\"  D95: {stats['D95']:.2f} Gy\")\n",
    "print(f\"  D50: {stats['D50']:.2f} Gy\")\n",
    "print(f\"  D05: {stats['D05']:.2f} Gy\")\n",
    "\n",
    "# Compute DVH\n",
    "dose_bins, volumes = dvh.compute_dvh(dose, ptv)\n",
    "print(f\"\\nDVH computed with {len(dose_bins)} dose bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173266d9",
   "metadata": {},
   "source": [
    "## 6. Low-Level NIfTI Operations (Advanced)\n",
    "\n",
    "For advanced use cases, you can access raw NIfTI data using low-level functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731a8a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Level Volume Access:\n",
      "------------------------------------------------------------\n",
      "  Shape: (128, 128, 128)\n",
      "  Spacing: (2.0, 2.0, 2.0)\n",
      "  Origin: (92.70909881591797, 80.26853942871094, 52.468624114990234)\n",
      "  Data type: float32\n",
      "\n",
      "Dictionary keys: ['image_volumes', 'structure_masks', 'dose_volume', 'dose_spacing', 'dose_origin', 'spacing', 'origin']\n",
      "\n",
      "Note: For most use cases, use the high-level Dose and StructureSet classes instead.\n"
     ]
    }
   ],
   "source": [
    "from dosemetrics.io import nifti_io, load_volume\n",
    "\n",
    "# Load individual volume with metadata (low-level)\n",
    "volume, spacing, origin = load_volume(dose_file)\n",
    "\n",
    "print(\"Low-Level Volume Access:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Shape: {volume.shape}\")\n",
    "print(f\"  Spacing: {spacing}\")\n",
    "print(f\"  Origin: {origin}\")\n",
    "print(f\"  Data type: {volume.dtype}\")\n",
    "\n",
    "# Load raw data as dictionary\n",
    "nifti_data_dict = nifti_io.load_nifti_folder(subject_path, return_as_structureset=False)\n",
    "print(f\"\\nDictionary keys: {list(nifti_data_dict.keys())}\")\n",
    "\n",
    "print(\"\\nNote: For most use cases, use the high-level Dose and StructureSet classes instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2eb93",
   "metadata": {},
   "source": [
    "## 7. Loading Specific Structure Masks\n",
    "\n",
    "You can load individual structure masks from NIfTI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16569c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainstem Mask:\n",
      "------------------------------------------------------------\n",
      "  File: Brainstem.nii.gz\n",
      "  Shape: (128, 128, 128)\n",
      "  Data type: uint8\n",
      "  Voxels in mask: 3,883\n",
      "  Spacing: (2.0, 2.0, 2.0)\n",
      "  Origin: (92.70909881591797, 80.26853942871094, 52.468624114990234)\n"
     ]
    }
   ],
   "source": [
    "# Load a specific structure mask\n",
    "brainstem_file = subject_path / \"Brainstem.nii.gz\"\n",
    "brainstem_mask, spacing, origin = load_volume(brainstem_file)\n",
    "\n",
    "print(\"Brainstem Mask:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  File: {brainstem_file.name}\")\n",
    "print(f\"  Shape: {brainstem_mask.shape}\")\n",
    "print(f\"  Data type: {brainstem_mask.dtype}\")\n",
    "print(f\"  Voxels in mask: {(brainstem_mask > 0).sum():,}\")\n",
    "print(f\"  Spacing: {spacing}\")\n",
    "print(f\"  Origin: {origin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275c7df",
   "metadata": {},
   "source": [
    "## 8. Analyzing Spatial Properties\n",
    "\n",
    "Extract spatial information from NIfTI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab8412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Properties:\n",
      "------------------------------------------------------------\n",
      "Grid dimensions (voxels): [128 128 128]\n",
      "Voxel spacing (mm): [2. 2. 2.]\n",
      "Physical dimensions (mm): [256. 256. 256.]\n",
      "Physical dimensions (cm): [25.6 25.6 25.6]\n",
      "\n",
      "Voxel volume: 8.000 mm³\n",
      "Total volume: 16777.2 cm³\n"
     ]
    }
   ],
   "source": [
    "# Calculate physical dimensions\n",
    "voxel_spacing = np.array(spacing)\n",
    "grid_dimensions = np.array(volume.shape)\n",
    "physical_dimensions = voxel_spacing * grid_dimensions\n",
    "\n",
    "print(\"Spatial Properties:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Grid dimensions (voxels): {grid_dimensions}\")\n",
    "print(f\"Voxel spacing (mm): {voxel_spacing}\")\n",
    "print(f\"Physical dimensions (mm): {physical_dimensions}\")\n",
    "print(f\"Physical dimensions (cm): {physical_dimensions / 10}\")\n",
    "print(f\"\\nVoxel volume: {np.prod(voxel_spacing):.3f} mm³\")\n",
    "print(f\"Total volume: {np.prod(physical_dimensions) / 1000:.1f} cm³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7a8a0",
   "metadata": {},
   "source": [
    "## 9. Format Detection\n",
    "\n",
    "DoseMetrics can automatically detect the format of data in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95571cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected format: nifti\n",
      "✓ Format is NIfTI as expected\n"
     ]
    }
   ],
   "source": [
    "from dosemetrics.io import detect_folder_format\n",
    "\n",
    "# Check what format a folder contains\n",
    "format_type = detect_folder_format(subject_path)\n",
    "print(f\"Detected format: {format_type}\")\n",
    "\n",
    "# Verify it's NIfTI\n",
    "assert format_type == 'nifti', f\"Expected 'nifti', got '{format_type}'\"\n",
    "print(\"✓ Format is NIfTI as expected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e3dba",
   "metadata": {},
   "source": [
    "## 10. Saving Data to NIfTI Format\n",
    "\n",
    "Export structure masks and dose distributions to NIfTI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed94d185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIfTI Export Capabilities:\n",
      "------------------------------------------------------------\n",
      "\n",
      "To save a volume (dose or mask) to NIfTI:\n",
      "  from dosemetrics.io import nifti_io\n",
      "  nifti_io.save_nifti(array, output_path, spacing, origin)\n",
      "\n",
      "To save all structures from a StructureSet:\n",
      "  for name in structures.structure_names:\n",
      "      mask = structures.get_structure(name).mask\n",
      "      output_file = output_dir / f'{name}.nii.gz'\n",
      "      nifti_io.save_nifti(mask, output_file, spacing, origin)\n",
      "\n",
      "✓ For detailed export examples, see the exporting-results notebook\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of saving capabilities\n",
    "# Note: We're not actually saving here to avoid cluttering the workspace\n",
    "\n",
    "print(\"NIfTI Export Capabilities:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nTo save a volume (dose or mask) to NIfTI:\")\n",
    "print(\"  from dosemetrics.io import nifti_io\")\n",
    "print(\"  nifti_io.save_nifti(array, output_path, spacing, origin)\")\n",
    "print(\"\\nTo save all structures from a StructureSet:\")\n",
    "print(\"  for name in structures.structure_names:\")\n",
    "print(\"      mask = structures.get_structure(name).mask\")\n",
    "print(\"      output_file = output_dir / f'{name}.nii.gz'\")\n",
    "print(\"      nifti_io.save_nifti(mask, output_file, spacing, origin)\")\n",
    "print(\"\\n✓ For detailed export examples, see the exporting-results notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f22f7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. ✓ Load NIfTI dose and structure data using `load_structure_set()`\n",
    "2. ✓ Work with the StructureSet API for convenient access\n",
    "3. ✓ Load individual NIfTI files with `load_volume()`\n",
    "4. ✓ Assign custom structure types (TARGET, OAR, etc.)\n",
    "5. ✓ Access spatial metadata (spacing, origin, dimensions)\n",
    "6. ✓ Use low-level NIfTI I/O functions for advanced control\n",
    "7. ✓ Analyze spatial properties and volumes\n",
    "8. ✓ Detect data format automatically\n",
    "9. ✓ Save data to NIfTI format\n",
    "\n",
    "## Key API Functions\n",
    "\n",
    "### High-level\n",
    "- `load_structure_set(folder_path)` - Auto-detect format and load all data\n",
    "- `load_volume(file_path)` - Load a single NIfTI file with metadata\n",
    "\n",
    "### Low-level\n",
    "- `nifti_io.load_nifti_folder(folder_path)` - Load all NIfTI files as dictionary\n",
    "- `nifti_io.save_nifti(array, path, spacing, origin)` - Save array to NIfTI\n",
    "\n",
    "### Utilities\n",
    "- `detect_folder_format(folder_path)` - Detect data format\n",
    "- `StructureType` - Enum for structure classification\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **DICOM I/O**: See [dicom-io.ipynb](dicom-io.ipynb) for DICOM operations\n",
    "- **Comparing Plans**: Learn how to compare treatment plans in [comparing-plans.ipynb](comparing-plans.ipynb)\n",
    "- **API Documentation**: Explore the full [DoseMetrics API](https://contouraid.github.io/dosemetrics/api/)\n",
    "\n",
    "## References\n",
    "\n",
    "- [DoseMetrics Documentation](https://contouraid.github.io/dosemetrics/)\n",
    "- [Dataset on HuggingFace](https://huggingface.co/datasets/contouraid/dosemetrics-data)\n",
    "- [GitHub Repository](https://github.com/contouraid/dosemetrics)\n",
    "- [NIfTI Format Specification](https://nifti.nimh.nih.gov/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dosemetrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
